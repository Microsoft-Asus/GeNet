{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'rg_data/'\n",
    "train_path = 'rg_references_short'\n",
    "\n",
    "ref_vocab_path = 'vocab.ref'\n",
    "lyr_vocab_path = 'vocab.lyr'\n",
    "\n",
    "ref_train_ids_path = \"rg_data/rg_references_train.ids40000.ref\"\n",
    "lyr_train_ids_path = \"rg_data/rg_lyrics_train.ids40000.lyr\"\n",
    "\n",
    "ref_val_ids_path = \"rg_data/rg_references_val.ids40000.ref\"\n",
    "lyr_val_ids_path = \"rg_data/rg_lyrics_val.ids40000.lyr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocabulary vocab.ref from data rg_references_train.csv\n",
      "  processing line 100000\n",
      "  processing line 200000\n",
      "Creating vocabulary vocab.lyr from data rg_lyrics_train.csv\n",
      "  processing line 100000\n",
      "  processing line 200000\n"
     ]
    }
   ],
   "source": [
    "data_utils.create_vocabulary(ref_vocab_path, 'rg_references_train.csv', 40000)\n",
    "data_utils.create_vocabulary(lyr_vocab_path, 'rg_lyrics_train.csv', 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data in rg_references_train.csv\n",
      "  tokenizing line 100000\n",
      "  tokenizing line 200000\n",
      "Tokenizing data in rg_lyrics_train.csv\n",
      "  tokenizing line 100000\n",
      "  tokenizing line 200000\n",
      "Tokenizing data in rg_references_val.csv\n",
      "Tokenizing data in rg_lyrics_val.csv\n"
     ]
    }
   ],
   "source": [
    "data_utils.data_to_token_ids(\"rg_references_train.csv\", ref_train_ids_path, ref_vocab_path)\n",
    "data_utils.data_to_token_ids(\"rg_lyrics_train.csv\", lyr_train_ids_path, lyr_vocab_path)\n",
    "\n",
    "data_utils.data_to_token_ids(\"rg_references_val.csv\", ref_val_ids_path, ref_vocab_path)\n",
    "data_utils.data_to_token_ids(\"rg_lyrics_val.csv\", lyr_val_ids_path, lyr_vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_utils.create_vocabulary('rg_references_short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get wmt data to the specified directory.\n",
    "train_path = get_wmt_enfr_train_set(data_dir)\n",
    "dev_path = get_wmt_enfr_dev_set(data_dir)\n",
    "\n",
    "# Create vocabularies of the appropriate sizes.\n",
    "fr_vocab_path = os.path.join(data_dir, \"vocab%d.fr\" % fr_vocabulary_size)\n",
    "en_vocab_path = os.path.join(data_dir, \"vocab%d.en\" % en_vocabulary_size)\n",
    "create_vocabulary(fr_vocab_path, train_path + \".fr\", fr_vocabulary_size)\n",
    "create_vocabulary(en_vocab_path, train_path + \".en\", en_vocabulary_size)\n",
    "\n",
    "# Create token ids for the training data.\n",
    "fr_train_ids_path = train_path + (\".ids%d.fr\" % fr_vocabulary_size)\n",
    "en_train_ids_path = train_path + (\".ids%d.en\" % en_vocabulary_size)\n",
    "data_to_token_ids(train_path + \".fr\", fr_train_ids_path, fr_vocab_path)\n",
    "data_to_token_ids(train_path + \".en\", en_train_ids_path, en_vocab_path)\n",
    "\n",
    "# Create token ids for the development data.\n",
    "fr_dev_ids_path = dev_path + (\".ids%d.fr\" % fr_vocabulary_size)\n",
    "en_dev_ids_path = dev_path + (\".ids%d.en\" % en_vocabulary_size)\n",
    "data_to_token_ids(dev_path + \".fr\", fr_dev_ids_path, fr_vocab_path)\n",
    "data_to_token_ids(dev_path + \".en\", en_dev_ids_path, en_vocab_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./ALL/input.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\n\\x0b\\x0c\\r '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50 Cent... Shady Records (Shady Records)\\nEminem (Eminem)...Dr. Dre (Dr. Dre)\\n\\nGGGGGGGG G-unit\\n\\n50 Cent, Shady, Aftermath\\n\\nThe Dreamteam\\n\\nWe got to get the get well cards\\nNiggas is sick\\n\\nFeel this\\n\\nMotion picture shit\\n\\n[Verse 1]\\nNow don\\'t think I won\\'t hit you because I\\'m popular, I got P-90 Ruger to pop at ya, catch you\\nSlipping I\\'m give you what I got for ya, my clip loaded with 16 shots for ya, you never had a hot gun\\nOn ya waste and blood on your shoe because a nigga went and said the wrong shit to you, homie\\nYou ain\\'t been threw what I been threw you not like me and I\\'m not like you\\n\\n[Verse 2]\\nI\\'m like an animal wit it when I spit it\\'s crazy, got semi-autos to put holes and niggas try to play me\\nOne shot is not enough you need at least a uzi to move me, after four bottles of don\\nThe kid start to feeling woozy, I write my life you write what you see in gangsta movies, I\\'m\\nGangsta to the core nigga you can\\'t move me, I find my space at the top I got this rap shit\\nLocked, I never heard of you you heard of me, I murder you, I spit shells to your convertible\\nLotis you notice Richer or poor hollow steel go through your door this is war\\nYou scare of me you not prepared for me the kid is back\\n50 cents I know you like that I know you like that{*set to Dr. Dre & Snoop\\'s \"Deep Cover\" instrumental*}\\n\\n[50 Cent]\\nG-G-G-G-G-G-Unit!\\n50 Cent nigga, Tony Yayo (yeah)\\n{WHOOOOOO... KID}\\n\\n[Hook: repeat 2X]\\nYeah! And you don\\'t stop\\nI do a 187 on your motherfuckin block\\nYeah! And it don\\'t quit\\nIt\\'s G-Unit in your motherfuckin ass bitch~!\\n\\n[Tony Yayo]\\nThey say good things should happen to those who wait\\nBut I\\'m stuck in the game still slingin weight\\nFor that eggshell white, that tan and the brown\\nFor a XL-6 or a seven four pound\\nSuede seats is hot but Italian leather is better\\nAnd with cameras in the mirror, nigga cars costs cheddar\\nI\\'m on first class flights, with flyin cooks\\nCause my verse sound nice when they fly in hooks\\nNow I\\'m blowin weed yo, in Beverly Hills\\nWith some bad freak ho'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = text.replace('.', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_chars = string.letters + string.digits + \"\\n\" + \" \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_chars = string.letters + string.digits + \"\\n\" + \" \" \n",
    "text_filt = \"\"\n",
    "\n",
    "for char in text:\n",
    "    if char in valid_chars:\n",
    "        text_filt += char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50 Cent    Shady Records Shady Records\\nEminem Eminem   Dr  Dre Dr  Dre\\n\\nGGGGGGGG Gunit\\n\\n50 Cent Shady Aftermath\\n\\nThe Dreamteam\\n\\nWe got to get the get well cards\\nNiggas is sick\\n\\nFeel this\\n\\nMotion picture shit\\n\\nVerse 1\\nNow dont think I wont hit you because Im popular I got P90 Ruger to pop at ya catch you\\nSlipping Im give you what I got for ya my clip loaded with 16 shots for ya you never had a hot gun\\nOn ya waste and blood on your shoe because a nigga went and said the wrong shit to you homie\\nYou aint been threw what I been threw you not like me and Im not like you\\n\\nVerse 2\\nIm like an animal wit it when I spit its crazy got semiautos to put holes and niggas try to play me\\nOne shot is not enough you need at least a uzi to move me after four bottles of don\\nThe kid start to feeling woozy I write my life you write what you see in gangsta movies Im\\nGangsta to the core nigga you cant move me I find my space at the top I got this rap shit\\nLocked I never heard of you you heard of me I murder yo'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_filt[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = text_filt.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_text = ' \\n '.join(lines[:-(val_size+test_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1807385"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_size = 100000\n",
    "test_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_file = open('./ALL/input_train.txt', 'w')\n",
    "val_file = open('./ALL/input_val.txt', 'w')\n",
    "test_file = open('./ALL/input_test.txt', 'w')\n",
    "\n",
    "train_end_idx = len(lines) - val_size - test_size\n",
    "val_end_idx = len(lines) - test_size\n",
    "\n",
    "train_text = ' \\n '.join(lines[:train_end_idx])\n",
    "val_text = ' \\n '.join(lines[train_end_idx:val_end_idx])\n",
    "test_text = ' \\n '.join(lines[val_end_idx:])\n",
    "\n",
    "train_file.write(train_text)\n",
    "val_file.write(val_text)\n",
    "test_file.write(test_text)\n",
    "\n",
    "train_file.close()\n",
    "val_file.close()\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
